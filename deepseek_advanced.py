# ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏à‡∏≤‡∏Å imported modules
import sys
import os
import warnings
from contextlib import redirect_stdout, redirect_stderr
import io
import time
import threading

# ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á warnings ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
warnings.filterwarnings("ignore", category=Warning)
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏±‡∏ö MPS
os.environ["TRANSFORMERS_NO_ADVISORY_WARNINGS"] = "1"

# ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô stdout
# ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
class StdoutFilter:
    def __init__(self):
        self.old_stdout = sys.stdout
        self.filtered_strings = [
            "Sliding Window Attention",
            "unexpected results may be encountered",
            "LibreSSL",
            "is compiled with",
            "setting `pad_token_id`",
            "urllib3"
        ]
    
    def write(self, text):
        # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å
        if not any(fstr in text for fstr in self.filtered_strings):
            self.old_stdout.write(text)
    
    def flush(self):
        self.old_stdout.flush()

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á stdout
original_stdout = sys.stdout
sys.stdout = StdoutFilter()

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏á‡∏µ‡∏¢‡∏ö
def suppress_output(func, *args, **kwargs):
    # ‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡∏≠‡∏á stdout ‡πÅ‡∏•‡∏∞ stderr
    stdout_buffer = io.StringIO()
    stderr_buffer = io.StringIO()
    
    with redirect_stdout(stdout_buffer), redirect_stderr(stderr_buffer):
        result = func(*args, **kwargs)
    
    return result

# ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°
# ‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏à‡∏≤‡∏Å imports
with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):
    from transformers import AutoModelForCausalLM, AutoTokenizer
    import torch

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏≤‡∏ò‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
model_path = "deepseek_model"

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("üì± ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ Apple Silicon (MPS)")
elif torch.cuda.is_available():
    device = torch.device("cuda")
    print("üñ•Ô∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ NVIDIA GPU (CUDA)")
else:
    device = torch.device("cpu")
    print("üíª ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ CPU (‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ä‡πâ‡∏≤)")

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ tokenizer ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢
print("\n‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏∞‡∏ö‡∏ö...")

try:
    # ‡πÇ‡∏´‡∏•‡∏î tokenizer
    print("   ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î tokenizer...")
    tokenizer = suppress_output(AutoTokenizer.from_pretrained, model_path)
    print("   ‚úì ‡πÇ‡∏´‡∏•‡∏î tokenizer ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
    
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
    print("   ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î model (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà)...")
    model = suppress_output(AutoModelForCausalLM.from_pretrained, model_path, 
                          low_cpu_mem_usage=True, torch_dtype=torch.float16)
    model = model.to(device)
    print("   ‚úì ‡πÇ‡∏´‡∏•‡∏î model ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
    
    print("\n‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß!\n")
except Exception as e:
    print(f"\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
    exit(1)

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏ä‡∏±‡∏ô "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î..."
def show_thinking_animation():
    animation_event = threading.Event()
    
    def animate():
        animation_chars = ["   ", ".  ", ".. ", "..."]
        i = 0
        while not animation_event.is_set():
            # ‡πÉ‡∏ä‡πâ stdout ‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏à‡∏≤‡∏Å StdoutFilter
            original_stdout.write(f"\rü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î{animation_chars[i % len(animation_chars)]}")
            original_stdout.flush()
            time.sleep(0.3)
            i += 1
        
        # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
        original_stdout.write("\r                       \r")
        original_stdout.flush()
    
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏ä‡∏±‡∏ô‡πÉ‡∏ô‡πÄ‡∏ò‡∏£‡∏î‡πÅ‡∏¢‡∏Å
    animation_thread = threading.Thread(target=animate)
    animation_thread.daemon = True
    animation_thread.start()
    
    # ‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏ä‡∏±‡∏ô
    def stop_animation():
        animation_event.set()
        animation_thread.join(timeout=1.0)
    
    return stop_animation

# ‡∏Ñ‡∏•‡∏≤‡∏™‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
class DeepSeekChat:
    def __init__(self, model, tokenizer, device):
        self.model = model
        self.tokenizer = tokenizer
        self.device = device
        self.history = []
        self.temperature = 0.7
        
        # ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°)
        self.faq_responses = {
            "‡∏Ç‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥": "‡∏ú‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡πÅ‡∏ï‡πà‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÄ‡∏ä‡πà‡∏ô '‡∏Ç‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ AI' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏Ç‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î'",
            "‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á": "‡∏ú‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î ‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÑ‡∏î‡πâ ‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?",
            "‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≠‡∏ô": "‡∏ú‡∏°‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≠‡∏ô ‡πÅ‡∏ï‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏™‡∏ô‡πÉ‡∏à‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ä‡πà‡∏ô '‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≠‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô Python' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á machine learning'",
            "‡πÄ‡∏ö‡∏∑‡πà‡∏≠": "‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ä‡∏≠‡∏ö‡∏ó‡∏≥‡∏î‡∏π‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö? ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ ‡∏î‡∏π‡∏´‡∏ô‡∏±‡∏á ‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏Å‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡πÉ‡∏´‡∏°‡πà‡πÜ ‡∏Ñ‡∏∏‡∏ì‡∏ä‡∏≠‡∏ö‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡∏ö?"
        }
        
    def generate_response(self, user_input, max_length=512):
        # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢‡πÜ)
        greetings = ["hi", "hello", "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "‡∏´‡∏ß‡∏±‡∏î‡∏î‡∏µ", "‡∏î‡∏µ"]
        how_are_you = ["‡∏™‡∏ö‡∏≤‡∏¢‡∏î‡∏µ‡πÑ‡∏´‡∏°", "‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á", "‡∏™‡∏ö‡∏≤‡∏¢‡∏î‡∏µ‡∏°‡∏±‡πâ‡∏¢", "how are you", "what's up"]
        goodbyes = ["bye", "goodbye", "‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô", "‡∏ö‡∏≤‡∏¢"]
        thanks = ["thanks", "thank you", "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì", "‡∏Ç‡∏≠‡∏ö‡πÉ‡∏à"]
        
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏≠‡∏∑‡πà‡∏ô‡πÜ
        common_qas = {
            "‡∏Ñ‡∏∏‡∏ì‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£": "‡∏â‡∏±‡∏ô‡∏ä‡∏∑‡πà‡∏≠ DeepSeek ‡∏â‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô AI ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ DeepSeek",
            "‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£": "‡∏â‡∏±‡∏ô‡∏ä‡∏∑‡πà‡∏≠ DeepSeek ‡∏â‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô AI ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ DeepSeek",
            "your name": "My name is DeepSeek. I'm an AI chatbot developed by DeepSeek.",
            "‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ": "‡∏â‡∏±‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÑ‡∏î‡πâ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏° ‡∏â‡∏±‡∏ô‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤",
            "what can you do": "I can chat with you, answer general questions, help solve problems, and explain concepts. However, I'm still in development.",
            "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Å‡πà‡∏á‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô": "‡∏â‡∏±‡∏ô‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á‡∏â‡∏±‡∏ô‡∏≠‡∏≤‡∏à‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÉ‡∏ô‡∏ö‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô ‡πÅ‡∏ï‡πà‡∏â‡∏±‡∏ô‡∏à‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏´‡πâ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î",
            "‡πÉ‡∏Ñ‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏∏‡∏ì": "‡∏â‡∏±‡∏ô‡∏ñ‡∏π‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ DeepSeek ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏≤‡∏ô AI ‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà",
            "who made you": "I was developed by DeepSeek, a company working on AI and large language models."
        }
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        user_input_lower = user_input.lower()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢
        if any(greeting in user_input_lower for greeting in greetings):
            return "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ?"
            
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡∏≤‡∏£‡∏ó‡∏∏‡∏Å‡∏Ç‡πå‡∏™‡∏∏‡∏Ç‡∏î‡∏¥‡∏ö
        if any(how in user_input_lower for how in how_are_you):
            return "‡∏ú‡∏°‡∏™‡∏ö‡∏≤‡∏¢‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ñ‡∏≤‡∏° ‡∏Ñ‡∏∏‡∏ì‡∏•‡πà‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á?"
            
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì
        if any(thank in user_input_lower for thank in thanks):
            return "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏≠‡∏µ‡∏Å ‡∏Å‡πá‡∏ö‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö"
            
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏•‡∏≤
        if any(bye in user_input_lower for bye in goodbyes):
            return "‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏à‡∏≤‡∏Å‡∏î‡∏¥‡∏Å‡∏ä‡∏±‡∏ô‡∏ô‡∏≤‡∏£‡∏µ
        for question, answer in common_qas.items():
            if question in user_input_lower:
                return answer
                
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÉ‡∏î‡πÜ ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÅ‡∏ï‡πà‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÉ‡∏´‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
        try:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏≠‡∏ö‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•
            prompt = f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {user_input}\n‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô: "
            
            inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
            
            # ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏Ç‡∏ì‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):
                    output = self.model.generate(
                        **inputs, 
                        max_length=max_length, 
                        do_sample=True, 
                        temperature=self.temperature,
                        top_p=0.9,
                        top_k=50,
                        repetition_penalty=1.2,
                        pad_token_id=self.tokenizer.eos_token_id,
                        eos_token_id=self.tokenizer.eos_token_id
                    )
            
            # ‡∏ñ‡∏≠‡∏î‡∏£‡∏´‡∏±‡∏™‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏≠‡∏≠‡∏Å
            full_response = self.tokenizer.decode(output[0], skip_special_tokens=True)
            
            # ‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° prompt ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö
            if prompt in full_response:
                response = full_response[len(prompt):].strip()
            else:
                # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
                response_marker = "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô: "
                if response_marker in full_response:
                    response = full_response.split(response_marker)[1].strip()
                else:
                    # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏ï‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
                    question_marker = f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {user_input}"
                    if question_marker in full_response:
                        response = full_response.split(question_marker)[1].strip()
                    else:
                        response = full_response.strip()
            
            # ‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
            if len(response) > 10:  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠
                # ‡∏ï‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô‡∏´‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
                for end_marker in ['.', '!', '?', ':', '\n\n']:
                    last_idx = response.rfind(end_marker)
                    if last_idx > len(response) * 0.7:  # ‡∏ï‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
                        response = response[:last_idx+1]
                        break
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏£‡∏ì‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏°‡∏ú‡∏•
            if len(response) < 5 or not any(char.isalpha() for char in response):
                return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏±‡πâ‡∏ô ‡∏Ñ‡∏∏‡∏ì‡∏ä‡πà‡∏ß‡∏¢‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö?"
                
            return response
        
        except Exception as e:
            return f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö: {str(e)}"

    def chat(self):
        print("\n" + "="*60)
        print("ü§ñ DeepSeek Chatbot ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£")
        print("üí¨ ‡∏û‡∏¥‡∏°‡∏û‡πå 'exit', '‡∏≠‡∏≠‡∏Å' ‡∏´‡∏£‡∏∑‡∏≠ 'quit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤")
        print("‚öôÔ∏è  ‡∏û‡∏¥‡∏°‡∏û‡πå '/help' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ")
        print("="*60 + "\n")
        
        while True:
            user_input = input("üë§ ‡∏Ñ‡∏∏‡∏ì: ").strip()
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏û‡∏¥‡πÄ‡∏®‡∏©
            if user_input.lower() in ["exit", "‡∏≠‡∏≠‡∏Å", "‡∏à‡∏ö", "quit", "bye"]:
                print("\nüëã ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô DeepSeek Chatbot")
                break
                
            elif user_input.lower() == "/help":
                print("\nüîç ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ:")
                print("  exit, ‡∏≠‡∏≠‡∏Å, quit - ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
                print("  /clear - ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤")
                print("  /temp [0.1-1.0] - ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ temperature (‡πÄ‡∏ä‡πà‡∏ô /temp 0.8)")
                print("  /help - ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ\n")
                continue
                
            elif user_input.lower() == "/clear":
                self.history = []
                print("\nüßπ ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏•‡πâ‡∏ß\n")
                continue
                
            elif user_input.lower().startswith("/temp "):
                try:
                    temp = float(user_input.split()[1])
                    if 0.1 <= temp <= 1.0:
                        self.temperature = temp
                        print(f"\nüå°Ô∏è ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ temperature ‡πÄ‡∏õ‡πá‡∏ô {temp} ‡πÅ‡∏•‡πâ‡∏ß\n")
                    else:
                        print("\n‚ö†Ô∏è ‡∏Ñ‡πà‡∏≤ temperature ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 0.1-1.0\n")
                except:
                    print("\n‚ö†Ô∏è ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: /temp 0.7\n")
                continue
                
            elif not user_input:
                continue

            # ‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏ä‡∏±‡∏ô‡∏Ñ‡∏¥‡∏î (‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏≤‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏ô‡∏≠‡∏Å)
            print()  # ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏ä‡∏±‡∏ô
            
            # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏ä‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏ä‡∏±‡∏ô
            stop_animation = show_thinking_animation()
            
            try:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
                response = self.generate_response(user_input)
            finally:
                # ‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏ä‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Ç‡∏∂‡πâ‡∏ô
                stop_animation()
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
            print(f"ü§ñ DeepSeek: {response}\n")
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
            self.history.append({"user": user_input, "bot": response})

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏ô‡∏™‡πÅ‡∏ï‡∏ô‡∏ã‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
if __name__ == "__main__":
    chatbot = DeepSeekChat(model, tokenizer, device)
    chatbot.chat()
